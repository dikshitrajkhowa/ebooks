https://linuxhint.com/install-apache-spark-ubuntu/

sudo dpkg --configure -a
sudo apt update
sudo apt install default-jdk

wget https://archive.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz
tar xvf spark-3.0.3-bin-hadoop2.7.tgz
sudo mv spark-3.0.3-bin-hadoop2.7/ /opt/spark

sudo nano ~/.profile
export SPARK_HOME=/opt/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
export PYSPARK_PYTHON=/usr/bin/python3

source ~/.profile

start-master.sh
 
https://localhost:8080/

start-slave.sh spark://<hostname>:7077
start-slave.sh spark://linuxlocal:7077

Additionally, you can limit the memory of the new workers as well by using “-m” flag: the command written below will start a slave with memory usage of 256MB: